# -*- coding: utf-8 -*-
"""UIDAI_HACKTHON_DATA_ANALYSIS

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vGceBzm6vBE8PRQWG7QytTCirI579Sc0

# **UIDAI DATA ANALYSIS**

### Problem Statement
Aadhaar is the backbone of India’s digital identity ecosystem. Understanding enrolment
and demographic trends is critical for ensuring inclusion, accessibility, and efficient
service delivery.

This project analyses UIDAI Aadhaar Enrolment and Demographic datasets to uncover
meaningful patterns, anomalies, and indicators that can support data-driven policy
decisions and system improvements.
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA

import warnings
warnings.filterwarnings("ignore")

plt.rcParams["figure.figsize"] = (10,6)
sns.set_style("whitegrid")

"""### Data Collection & Integration

Load and merge UIDAI dataset
"""

# Demographic datasets
demo_files = [
    "api_data_aadhar_demographic_0_500000.csv",
    "api_data_aadhar_demographic_500000_1000000.csv",
    "api_data_aadhar_demographic_1000000_1500000.csv",
    "api_data_aadhar_demographic_1500000_2000000.csv",
    "api_data_aadhar_demographic_2000000_2071700.csv"
]

# Enrolment datasets
enrol_files = [
    "api_data_aadhar_enrolment_0_500000.csv",
    "api_data_aadhar_enrolment_500000_1000000.csv",
    "api_data_aadhar_enrolment_1000000_1006029.csv"
]

demographics = pd.concat([pd.read_csv(f) for f in demo_files], ignore_index=True)
enrolment = pd.concat([pd.read_csv(f) for f in enrol_files], ignore_index=True)

print("Demographics shape:", demographics.shape)
print("Enrolment shape:", enrolment.shape)

"""### Data Cleaning & Validation (Audit-Proof)

Remove Duplicates
"""

print("Before cleaning demographics:", demographics.shape)
demographics.drop_duplicates(inplace=True)
print("After cleaning demographics:", demographics.shape)

print("Before cleaning enrolment:", enrolment.shape)
enrolment.drop_duplicates(inplace=True)
print("After cleaning enrolment:", enrolment.shape)

"""Standardize State Names (Critical)"""

state_mapping = {
    "TELENGANA": "TELANGANA",
    "ODISHA ": "ODISHA",
    "DELHI NCT": "DELHI",
    "ANDAMAN & NICOBAR": "ANDAMAN AND NICOBAR"
}

enrolment["state"] = (
    enrolment["state"]
    .str.upper()
    .str.strip()
    .replace(state_mapping)
)

"""### Data Understanding, Cleaning & Quality Assessment

Data Understanding, Cleaning & Quality Assessment
"""

demographics.info()
enrolment.info()

demographics.describe(include="all")
enrolment.describe(include="all")

"""Duplicate Record Removal"""

demographics.drop_duplicates(inplace=True)
enrolment.drop_duplicates(inplace=True)

"""Missing Value Analysis"""

print("Missing % in Demographics DataFrame:")
print((demographics.isna().sum() / demographics.shape[0] * 100).round(2))

print("\nMissing % in Enrolment DataFrame:")
print((enrolment.isna().sum() / enrolment.shape[0] * 100).round(2))

"""### Advanced Data Cleaning & Quality Resolution

### Issue Identification: High Missing Date Values

Initial data profiling revealed that approximately 46–47% of records in both
Demographics and Enrolment datasets contained missing or invalid date values.
Since these dates are critical for temporal analysis, they require explicit handling.

### Date Parsing & Validation
Convert date columns to datetime format
"""

demographics["date"] = pd.to_datetime(demographics["date"], errors="coerce")
enrolment["date"] = pd.to_datetime(enrolment["date"], errors="coerce")

print("Demographics DataFrame info after date conversion:")
demographics.info()
print("\nEnrolment DataFrame info after date conversion:")
enrolment.info()

"""### Removal of Unreliable Date Records"""

initial_demographics_rows = demographics.shape[0]
demographics.dropna(subset=["date"], inplace=True)
dropped_demographics_rows = initial_demographics_rows - demographics.shape[0]

initial_enrolment_rows = enrolment.shape[0]
enrolment.dropna(subset=["date"], inplace=True)
dropped_enrolment_rows = initial_enrolment_rows - enrolment.shape[0]

print(f"Dropped {dropped_demographics_rows} rows with missing dates from Demographics DataFrame.")
print(f"Demographics DataFrame shape after dropping NaT dates: {demographics.shape}")

print(f"Dropped {dropped_enrolment_rows} rows with missing dates from Enrolment DataFrame.")
print(f"Enrolment DataFrame shape after dropping NaT dates: {enrolment.shape}")

print("\nMissing % after dropping NaT dates - Demographics:")
print((demographics.isna().sum() / demographics.shape[0] * 100).round(2))

print("\nMissing % after dropping NaT dates - Enrolment:")
print((enrolment.isna().sum() / enrolment.shape[0] * 100).round(2))

"""### Text Standardization (State & District Normalization)

To ensure consistency and accuracy, I need to standardize the 'state' and 'district' columns in both DataFrames by converting them to uppercase and stripping any leading/trailing whitespace. This will help in unifying entries that might have slight variations in casing or spacing.


"""

if "state" in demographics.columns:
    demographics["state"] = demographics["state"].astype(str).str.upper().str.strip()
    print("Standardized 'state' column in Demographics.")

if "district" in demographics.columns:
    demographics["district"] = demographics["district"].astype(str).str.upper().str.strip()
    print("Standardized 'district' column in Demographics.")

if "state" in enrolment.columns:
    enrolment["state"] = enrolment["state"].astype(str).str.upper().str.strip()
    print("Standardized 'state' column in Enrolment.")

if "district" in enrolment.columns:
    enrolment["district"] = enrolment["district"].astype(str).str.upper().str.strip()
    print("Standardized 'district' column in Enrolment.")

print("\nVerifying info after text standardization:")
demographics.info()
enrolment.info()

"""## Verify Cleaning and Summarize

After cleaning, verify the data types and check the percentage of missing values in both DataFrames to ensure the cleaning was effective. Provide a summary of the cleaning operations performed.

"""

print("--- Verification and Summary ---")

# 1. Verify data types and non-null counts
print("\nDemographics DataFrame info after cleaning:")
demographics.info()
print("\nEnrolment DataFrame info after cleaning:")
enrolment.info()

# 2. Calculate and display the percentage of missing values
print("\nMissing % after cleaning - Demographics:")
print((demographics.isna().sum() / demographics.shape[0] * 100).round(2))

print("\nMissing % after cleaning - Enrolment:")
print((enrolment.isna().sum() / enrolment.shape[0] * 100).round(2))

# --- Prepare for Summary (Re-capture initial states for accurate summary) ---

demo_files_local = [
    "api_data_aadhar_demographic_0_500000.csv",
    "api_data_aadhar_demographic_500000_1000000.csv",
    "api_data_aadhar_demographic_1000000_1500000.csv",
    "api_data_aadhar_demographic_1500000_2000000.csv",
    "api_data_aadhar_demographic_2000000_2071700.csv"
]

enrol_files_local = [
    "api_data_aadhar_enrolment_0_500000.csv",
    "api_data_aadhar_enrolment_500000_1000000.csv",
    "api_data_aadhar_enrolment_1000000_1006029.csv"
]

# Reload raw data to get initial shapes and duplicate counts accurately
raw_demographics = pd.concat([pd.read_csv(f) for f in demo_files_local], ignore_index=True)
raw_enrolment = pd.concat([pd.read_csv(f) for f in enrol_files_local], ignore_index=True)

initial_demographics_shape = raw_demographics.shape
initial_enrolment_shape = raw_enrolment.shape

initial_demographics_date_missing_pct = raw_demographics["date"].isna().sum() / initial_demographics_shape[0] * 100
initial_enrolment_date_missing_pct = raw_enrolment["date"].isna().sum() / initial_enrolment_shape[0] * 100

dup_demographics_count = raw_demographics.duplicated().sum()
dup_enrolment_count = raw_enrolment.duplicated().sum()

# --- 3. Detailed Summary of Cleaning Operations ---
print("\n\n--- Cleaning Operations Summary ---")

print(f"Initial Demographics DataFrame shape: {initial_demographics_shape}")
print(f"Initial Enrolment DataFrame shape: {initial_enrolment_shape}")

print(f"Final Demographics DataFrame shape: {demographics.shape}")
print(f"Final Enrolment DataFrame shape: {enrolment.shape}")

print(f"Number of duplicate rows removed from Demographics: {dup_demographics_count}")
print(f"Number of duplicate rows removed from Enrolment: {dup_enrolment_count}")

print(f"Percentage of missing 'date' in Demographics before dropping NaT: {initial_demographics_date_missing_pct:.2f}%")
print(f"Percentage of missing 'date' in Enrolment before dropping NaT: {initial_enrolment_date_missing_pct:.2f}%")
print(f"Percentage of missing 'date' in Demographics after dropping NaT: {(demographics['date'].isna().sum() / demographics.shape[0] * 100):.2f}%")
print(f"Percentage of missing 'date' in Enrolment after dropping NaT: {(enrolment['date'].isna().sum() / enrolment.shape[0] * 100):.2f}%")

print("\nMethods used for date conversion and handling NaT values:")
print("- `pd.to_datetime` with `errors='coerce'` was used to convert the 'date' column to datetime objects, turning unparseable dates into `NaT`.")
print('- Rows containing `NaT` values in the \'date\' column were subsequently dropped using `dropna(subset=["date"])`.')

print("\nMethods used for text standardization:")
print("- The 'state' and 'district' columns in both DataFrames were converted to string type, then transformed to uppercase using `.str.upper()` and had leading/trailing whitespace removed using `.str.strip()` to ensure consistency.")

"""## Summary:

The task required addressing missing date values, handling unparseable dates, verifying data types, and providing a detailed summary of cleaning operations.

1.  **Missing date values (originally 46-47%) in `demographics` and `enrolment` DataFrames were addressed:**
    *   In `demographics`, 921,732 rows (approximately 57.68\% of the initial 1,598,099 entries) had unparseable or missing date values. These rows were dropped.
    *   In `enrolment`, 663,354 rows (approximately 67.48\% of the initial 983,072 entries) had unparseable or missing date values. These rows were also dropped.
    *   After dropping these rows, both DataFrames have 0.0\% missing values in their 'date' columns.

2.  **Unparseable dates were handled by dropping rows with `NaT` dates:**
    *   `pd.to_datetime` with `errors='coerce'` was used to convert 'date' columns, turning unparseable strings into `NaT`.
    *   Subsequently, all rows where the 'date' column was `NaT` were removed from both DataFrames.

3.  **Data types of all columns were verified and a detailed summary of cleaning operations was provided:**
    *   After cleaning, the 'date' columns in both DataFrames were successfully converted to `datetime64[ns]`.
    *   'state' and 'district' columns were standardized (converted to uppercase and stripped of whitespace), remaining as `object` data type. Numerical columns (`pincode`, `demo_age_5_17`, `demo_age_17_`, `age_0_5`, `age_5_17`, `age_18_greater`) maintained their `int64` data type.
    *   All columns in both `demographics` and `enrolment` DataFrames showed 0.0\% missing values after the cleaning process.
    *   A comprehensive summary covering initial/final shapes, duplicate rows removed, and methods used for date conversion and text standardization was generated.

### Data Analysis Key Findings
*   **Date Column Conversion and Missing Value Handling**:
    *   The 'date' column in the `demographics` DataFrame was converted to `datetime64[ns]`, resulting in 921,732 `NaT` values (57.68\% of initial 1,598,099 entries). These rows were dropped.
    *   The 'date' column in the `enrolment` DataFrame was converted to `datetime64[ns]`, resulting in 663,354 `NaT` values (67.48\% of initial 983,072 entries). These rows were also dropped.
    *   After dropping rows with `NaT` dates, both `demographics` and `enrolment` DataFrames achieved 0.0\% missing values for their 'date' columns.
*   **DataFrame Shape Changes**:
    *   The `demographics` DataFrame was reduced from an initial shape of (2,071,700, 6) to a final shape of (676,367, 6).
    *   The `enrolment` DataFrame was reduced from an initial shape of (1,006,029, 7) to a final shape of (319,718, 7).
*   **Duplicate Rows Removed**:
    *   473,601 duplicate rows were identified and removed from the `demographics` DataFrame.
    *   22,957 duplicate rows were identified and removed from the `enrolment` DataFrame.
*   **Text Standardization**:
    *   The 'state' and 'district' columns in both DataFrames were standardized by converting them to uppercase and removing leading/trailing whitespace, ensuring consistency.
*   **Final Data Quality**: After all cleaning operations, both DataFrames have appropriate data types for all columns and no missing values.

## Review Current Cleaning Status

### Summary of Cleaning Operations:

*   **Initial DataFrames:**
    *   `raw_demographics`: (2,071,700, 6)
    *   `raw_enrolment`: (1,006,029, 7)

*   **Duplicate Removal:**
    *   473,601 duplicate rows were removed from `demographics`.
    *   22,957 duplicate rows were removed from `enrolment`.

*   **Date Column Conversion & NaT Handling:**
    *   The 'date' column in both DataFrames was converted to `datetime64[ns]` using `pd.to_datetime(errors='coerce')`.
    *   This resulted in a significant number of `NaT` values, which were subsequently dropped:
        *   921,732 rows (approx. 57.68%) with missing dates were dropped from `demographics`.
        *   663,354 rows (approx. 67.48%) with missing dates were dropped from `enrolment`.

*   **Text Standardization:**
    *   'state' and 'district' columns in both DataFrames were standardized by converting them to uppercase (`.str.upper()`) and removing leading/trailing whitespace (`.str.strip()`).

*   **Final DataFrames Shapes (after all cleaning):**
    *   `demographics`: (676,367, 6)
    *   `enrolment`: (319,718, 7)

*   **Missing Value Percentages (before NaT drop):**
    *   `demographics` 'date': 0.00% (initially, before coercion, then high after coercion)
    *   `enrolment` 'date': 0.00% (initially, before coercion, then high after coercion)

*   **Missing Value Percentages (after all cleaning):**
    *   All columns in both DataFrames now have 0.00% missing values.

### Current State Verification:
"""

print("\nDemographics DataFrame info after cleaning:")
demographics.info()
print("\nEnrolment DataFrame info after cleaning:")
enrolment.info()

print("\nMissing % after cleaning - Demographics:")
print((demographics.isna().sum() / demographics.shape[0] * 100).round(2))

print("\nMissing % after cleaning - Enrolment:")
print((enrolment.isna().sum() / enrolment.shape[0] * 100).round(2))

"""## Feature Engineering (Time and Age Aggregation)

Extract additional time-based features (year, month, quarter) from the 'date' column in both DataFrames. Create meaningful age group features by aggregating the existing age range columns (`age_0_5`, `age_5_17`, `age_18_greater` for enrolment and `demo_age_5_17`, `demo_age_17_` for demographics) to enable consistent age-based analysis.

"""

demographics["year"] = demographics["date"].dt.year
demographics["month"] = demographics["date"].dt.month
demographics["quarter"] = demographics["date"].dt.quarter

enrolment["year"] = enrolment["date"].dt.year
enrolment["month"] = enrolment["date"].dt.month
enrolment["quarter"] = enrolment["date"].dt.quarter

print("Extracted year, month, and quarter for both DataFrames.")

""" create new age group features for both `demographics` and `enrolment` DataFrames by aggregating existing age columns and calculating their proportions.




"""

demographics["total_population"] = demographics["demo_age_5_17"] + demographics["demo_age_17_"]
demographics["prop_age_5_17"] = demographics["demo_age_5_17"] / demographics["total_population"]
demographics["prop_age_17_plus"] = demographics["demo_age_17_"] / demographics["total_population"]

enrolment["total_enrolments"] = enrolment["age_0_5"] + enrolment["age_5_17"] + enrolment["age_18_greater"]
enrolment["prop_age_0_5"] = enrolment["age_0_5"] / enrolment["total_enrolments"]
enrolment["prop_age_5_17_enrol"] = enrolment["age_5_17"] / enrolment["total_enrolments"]
enrolment["prop_age_18_plus_enrol"] = enrolment["age_18_greater"] / enrolment["total_enrolments"]

print("Created age group features and proportions for both DataFrames.")

print("\nDemographics DataFrame head:")
demographics.head()

print("\nEnrolment DataFrame head:")
enrolment.head()

print("\nDemographics DataFrame info:")
demographics.info()

print("\nEnrolment DataFrame info:")
enrolment.info()

"""The previous step introduced NaNs in the proportion columns where the total population or total enrolments were zero, leading to division by zero. I need to handle these NaNs by filling them with 0 to ensure data integrity for subsequent analysis."""

demographics["prop_age_5_17"] = demographics["prop_age_5_17"].fillna(0)
demographics["prop_age_17_plus"] = demographics["prop_age_17_plus"].fillna(0)

enrolment["prop_age_0_5"] = enrolment["prop_age_0_5"].fillna(0)
enrolment["prop_age_5_17_enrol"] = enrolment["prop_age_5_17_enrol"].fillna(0)
enrolment["prop_age_18_plus_enrol"] = enrolment["prop_age_18_plus_enrol"].fillna(0)

print("Filled NaNs in proportion columns with 0.")

print("\nDemographics DataFrame info after NaN handling:")
demographics.info()

print("\nEnrolment DataFrame info after NaN handling:")
enrolment.info()

"""## Outlier Detection and Treatment

Identify and analyze potential outliers in relevant numerical columns within both DataFrames using statistical methods (e.g., IQR, Z-score) and visualizations (e.g., boxplots). Determine and apply suitable treatment strategies, such as capping, transformation, or removal, based on the nature of the data and the analysis goals.

define the `treat_outliers_iqr` function, which will calculate IQR and cap outliers. This function is essential for applying a consistent outlier treatment method to multiple numerical columns in both DataFrames.
"""

def treat_outliers_iqr(series):
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Count original outliers for summary
    outliers_before = ((series < lower_bound) | (series > upper_bound)).sum()

    # Cap values
    capped_series = series.clip(lower=lower_bound, upper=upper_bound)

    # Count capped values (difference from original, as clip replaces them)
    capped_values = (series != capped_series).sum()

    return capped_series, capped_values

print("Defined function: treat_outliers_iqr")

""" apply the `treat_outliers_iqr` function to the specified numerical columns in both `demographics` and `enrolment` DataFrames to cap outliers, and then print the number of capped values for each column.


"""

capped_values_summary = {}

# Demographics DataFrame
demo_cols_to_treat = ["demo_age_5_17", "demo_age_17_", "total_population"]
print("Treating outliers in Demographics DataFrame:")
for col in demo_cols_to_treat:
    if col in demographics.columns:
        demographics[col], capped_count = treat_outliers_iqr(demographics[col])
        capped_values_summary[f'demographics_{col}'] = capped_count
        print(f"  - Column '{col}': {capped_count} values capped.")

# Enrolment DataFrame
enrol_cols_to_treat = ["age_0_5", "age_5_17", "age_18_greater", "total_enrolments"]
print("\nTreating outliers in Enrolment DataFrame:")
for col in enrol_cols_to_treat:
    if col in enrolment.columns:
        enrolment[col], capped_count = treat_outliers_iqr(enrolment[col])
        capped_values_summary[f'enrolment_{col}'] = capped_count
        print(f"  - Column '{col}': {capped_count} values capped.")

print("\nOutlier treatment applied to specified columns.")

""" outliers have been treated,  create boxplots for each treated numerical column in both DataFrames to visualize the distribution after capping,:


"""

print("\nVisualizing distributions after outlier treatment:")

# Demographics DataFrame Boxplots
for col in demo_cols_to_treat:
    if col in demographics.columns:
        plt.figure(figsize=(8, 6))
        sns.boxplot(y=demographics[col])
        plt.title(f'Demographics: Boxplot of {col} (After Outlier Treatment)')
        plt.ylabel(col)
        plt.grid(True)
        plt.show()

# Enrolment DataFrame Boxplots
for col in enrol_cols_to_treat:
    if col in enrolment.columns:
        plt.figure(figsize=(8, 6))
        sns.boxplot(y=enrolment[col])
        plt.title(f'Enrolment: Boxplot of {col} (After Outlier Treatment)')
        plt.ylabel(col)
        plt.grid(True)
        plt.show()

print("Boxplots generated for treated numerical columns.")

"""


 create a bar chart showing the distribution of 'total_enrolments' across different 'year' values,
"""

print("Generating bar chart for total enrolments by year:")

enrolment_by_year = merged_df.groupby('year')['total_enrolments'].sum().reset_index()

plt.figure(figsize=(10, 6))
sns.barplot(data=enrolment_by_year, x='year', y='total_enrolments', palette='cividis')
plt.title('Total Enrolments by Year')
plt.xlabel('Year')
plt.ylabel('Total Enrolments')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

print("Bar chart for total enrolments by year generated.")

"""
 create a bar chart showing the distribution of 'total_enrolments' across different 'month' values,

"""

print("Generating bar chart for total enrolments by month:")

enrolment_by_month = merged_df.groupby('month')['total_enrolments'].sum().reset_index()

plt.figure(figsize=(10, 6))
sns.barplot(data=enrolment_by_month, x='month', y='total_enrolments', palette='magma')
plt.title('Total Enrolments by Month')
plt.xlabel('Month')
plt.ylabel('Total Enrolments')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

print("Bar chart for total enrolments by month generated.")

"""create a line plot to visualize the overall monthly trend of 'total_enrolments' over time by aggregating 'total_enrolments' by 'year' and 'month', sorting the results by date, and then plotting the trend,

"""

print("Generating line plot for overall monthly trend of total enrolments:")

enrolment_monthly_trend = merged_df.groupby(['year', 'month'])['total_enrolments'].sum().reset_index()
enrolment_monthly_trend['date'] = pd.to_datetime(enrolment_monthly_trend['year'].astype(str) + '-' + enrolment_monthly_trend['month'].astype(str))
enrolment_monthly_trend = enrolment_monthly_trend.sort_values('date')

plt.figure(figsize=(14, 7))
sns.lineplot(data=enrolment_monthly_trend, x='date', y='total_enrolments', marker='o', color='darkgreen')
plt.title('Overall Monthly Trend of Total Enrolments')
plt.xlabel('Date')
plt.ylabel('Total Enrolments')
plt.grid(True)
plt.tight_layout()
plt.show()

print("Line plot for monthly enrolment trend generated.")

"""

 create a line plot to visualize the overall monthly trend of 'total_population' over time by aggregating 'total_population' by 'year' and 'month', sorting the results by date, and then plotting the trend,

"""

print("Generating line plot for overall monthly trend of total population:")

population_monthly_trend = merged_df.groupby(['year', 'month'])['total_population'].sum().reset_index()
population_monthly_trend['date'] = pd.to_datetime(population_monthly_trend['year'].astype(str) + '-' + population_monthly_trend['month'].astype(str))
population_monthly_trend = population_monthly_trend.sort_values('date')

plt.figure(figsize=(14, 7))
sns.lineplot(data=population_monthly_trend, x='date', y='total_population', marker='o', color='darkblue')
plt.title('Overall Monthly Trend of Total Population')
plt.xlabel('Date')
plt.ylabel('Total Population')
plt.grid(True)
plt.tight_layout()
plt.show()

print("Line plot for monthly population trend generated.")

"""## Bivariate and Multivariate Analysis and Visualizations

Conduct bivariate and multivariate analysis to explore relationships between variables. Create diverse visualizations such as grouped bar charts (e.g., enrolment by state and aggregated age group), boxplots (e.g., distribution of enrolment counts across states), line plots showing temporal trends for different states, and heatmaps to visualize enrolment intensity across states and time periods.

create a grouped bar chart to visualize the distribution of total enrolments across different age groups for the top 10 states by total enrolments,
"""

print("Generating grouped bar chart for total enrolments across age groups for top 10 states:")

# Get top 10 states by total enrolments
top_10_states = merged_df.groupby('state')['total_enrolments'].sum().nlargest(10).index
df_top_10_states = merged_df[merged_df['state'].isin(top_10_states)]

# Aggregate age group enrolments for these states
agg_age_groups = df_top_10_states.groupby('state')[['age_0_5', 'age_5_17', 'age_18_greater']].sum().reset_index()

# Melt the DataFrame for grouped bar chart
agg_age_groups_melted = agg_age_groups.melt(id_vars='state', var_name='Age Group', value_name='Total Enrolments')

plt.figure(figsize=(15, 8))
sns.barplot(data=agg_age_groups_melted, x='state', y='Total Enrolments', hue='Age Group', palette='viridis')
plt.title('Total Enrolments by Age Group for Top 10 States')
plt.xlabel('State')
plt.ylabel('Total Enrolments')
plt.xticks(rotation=45, ha='right')
plt.legend(title='Age Group', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

print("Grouped bar chart generated.")

"""generate a boxplot to display the distribution of 'total_enrolments' across the top 10 states, This will help visualize the spread and central tendency of enrolments for each state.


"""

print("Generating boxplot for total enrolments across top 10 states:")

plt.figure(figsize=(15, 8))
sns.boxplot(data=df_top_10_states, x='state', y='total_enrolments', palette='viridis')
plt.title('Distribution of Total Enrolments Across Top 10 States')
plt.xlabel('State')
plt.ylabel('Total Enrolments')
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

print("Boxplot for total enrolments across top 10 states generated.")

""" create line plots showing the monthly temporal trends of 'total_enrolments' for a selection of the top 5 states,  This will involve aggregating data, creating a date column, and then plotting for each state.


"""

print("Generating line plots for monthly temporal trends of total enrolments for top 5 states:")

# Get top 5 states by total enrolments from the previously identified top 10
top_5_states = merged_df.groupby('state')['total_enrolments'].sum().nlargest(5).index.tolist()
df_top_5_states = merged_df[merged_df['state'].isin(top_5_states)]

# Aggregate monthly enrolments for these top 5 states
monthly_trend_top_5_states = df_top_5_states.groupby(['state', 'year', 'month'])['total_enrolments'].sum().reset_index()
monthly_trend_top_5_states['date'] = pd.to_datetime(monthly_trend_top_5_states['year'].astype(str) + '-' + monthly_trend_top_5_states['month'].astype(str))
monthly_trend_top_5_states = monthly_trend_top_5_states.sort_values(['state', 'date'])

plt.figure(figsize=(16, 9))
sns.lineplot(data=monthly_trend_top_5_states, x='date', y='total_enrolments', hue='state', marker='o', palette='tab10')
plt.title('Monthly Enrolment Trends for Top 5 States')
plt.xlabel('Date')
plt.ylabel('Total Enrolments')
plt.xticks(rotation=45)
plt.grid(True)
plt.legend(title='State', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

print("Line plots for monthly enrolment trends for top 5 states generated.")

"""

generate a heatmap to visualize the enrolment intensity across states and time periods (year-month) using the sum of 'total_enrolments',

"""

print("Generating heatmap for enrolment intensity across states and year-month periods:")

# Aggregate total enrolments by state and year-month
enrolment_heatmap_data = merged_df.groupby(['state', 'year', 'month'])['total_enrolments'].sum().reset_index()

# Create a combined year-month column for the heatmap
enrolment_heatmap_data['year_month'] = enrolment_heatmap_data['year'].astype(str) + '-' + enrolment_heatmap_data['month'].astype(str).str.zfill(2)

# Pivot the data to create the heatmap matrix
heatmap_pivot = enrolment_heatmap_data.pivot_table(index='state', columns='year_month', values='total_enrolments', fill_value=0)

plt.figure(figsize=(20, 10)) # Adjust figure size for better readability
sns.heatmap(heatmap_pivot, cmap='YlGnBu', linewidths=0.5, linecolor='white')
plt.title('Enrolment Intensity Across States and Time Periods')
plt.xlabel('Year-Month')
plt.ylabel('State')
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

print("Heatmap for enrolment intensity generated.")

"""## Anomaly Detection

Implement an anomaly detection mechanism to identify unusual patterns or outliers in the aggregated temporal enrolment data, providing insights into potential significant events or data discrepancies.

aggregate the `total_enrolments` from the `merged_df` by 'year' and 'month' to create a monthly time series, and then reset the index,
"""

monthly_enrolment_ts = merged_df.groupby(['year', 'month'])['total_enrolments'].sum().reset_index()

print("Monthly enrolment time series created:")
print(monthly_enrolment_ts.head())

""" create a 'date' column in the `monthly_enrolment_ts` DataFrame by combining the 'year' and 'month' columns and converting them to datetime objects,

"""

monthly_enrolment_ts['date'] = pd.to_datetime(monthly_enrolment_ts['year'].astype(str) + '-' + monthly_enrolment_ts['month'].astype(str) + '-01')

print("Added 'date' column to monthly_enrolment_ts DataFrame:")
print(monthly_enrolment_ts.head())

""" calculate the mean and standard deviation of the `total_enrolments` column in the `monthly_enrolment_ts` DataFrame,

"""

mean_enrolments = monthly_enrolment_ts['total_enrolments'].mean()
std_enrolments = monthly_enrolment_ts['total_enrolments'].std()

print(f"Mean of total enrolments: {mean_enrolments:.2f}")
print(f"Standard deviation of total enrolments: {std_enrolments:.2f}")

"""


 identify anomalies by creating a new boolean column named 'anomaly' in `monthly_enrolment_ts`, marking data points that deviate by more than 2 standard deviations from the mean as `True`,
"""

monthly_enrolment_ts['anomaly'] = (monthly_enrolment_ts['total_enrolments'] > mean_enrolments + 2 * std_enrolments) | \
                                (monthly_enrolment_ts['total_enrolments'] < mean_enrolments - 2 * std_enrolments)

print("Anomalies identified and 'anomaly' column added to monthly_enrolment_ts DataFrame:")
print(monthly_enrolment_ts.head())

"""I will create a scatter plot using `sns.scatterplot()` to visualize the monthly enrolments and highlight the anomalies, as specified in the fifth instruction. I will also add a title, labels, and rotate x-axis labels for better readability,


"""

plt.figure(figsize=(14, 7))
sns.scatterplot(data=monthly_enrolment_ts, x='date', y='total_enrolments', hue='anomaly', palette='coolwarm', s=100)
plt.title('Monthly Enrolment Anomaly Detection')
plt.xlabel('Date')
plt.ylabel('Total Enrolments')
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()

print("Scatter plot for monthly enrolment anomaly detection generated.")

"""## Predictive Trend Analysis

Implement predictive trend analysis on the aggregated temporal enrolment data to forecast future trends and provide insights into potential growth or decline.

add a numerical time index column 't' to the `monthly_enrolment_ts` DataFrame, representing sequential time points starting from 0,
"""

monthly_enrolment_ts['t'] = np.arange(len(monthly_enrolment_ts))

print("Added numerical time index 't' to monthly_enrolment_ts DataFrame:")
print(monthly_enrolment_ts.head())

""" instantiate a `LinearRegression` model from `sklearn.linear_model` to prepare for training the predictive trend model,


"""

lr_model = LinearRegression()

print("LinearRegression model instantiated.")

"""

 train the linear regression model using the 't' column as the independent variable (X) and 'total_enrolments' as the dependent variable (y),
"""

X = monthly_enrolment_ts[['t']]
y = monthly_enrolment_ts['total_enrolments']
lr_model.fit(X, y)

print("Linear regression model trained using 't' and 'total_enrolments'.")

""" predict the enrolment trend for the existing time period using the trained model and store these predictions in a new column named 'trend_pred' in the `monthly_enrolment_ts` DataFrame,





"""

monthly_enrolment_ts['trend_pred'] = lr_model.predict(X)

print("Predicted enrolment trend for existing period and added 'trend_pred' column.")
print(monthly_enrolment_ts.head())

""" create an array of future time steps for the next 6 months, starting from the last existing 't' value in `monthly_enrolment_ts`,


"""

last_t = monthly_enrolment_ts['t'].iloc[-1]
future_t = np.arange(last_t + 1, last_t + 1 + 6).reshape(-1, 1)

print(f"Future time steps created: {future_t.flatten()}")

"""predict future enrolment values for these future time steps using the trained linear regression model,

"""

future_predictions = lr_model.predict(future_t)

print("Predicted future enrolment values:")
print(future_predictions)

"""
create a new DataFrame for the future predictions, including a 'date' column representing the forecasted months and the predicted enrolment values,

"""

future_dates = pd.date_range(start=monthly_enrolment_ts['date'].iloc[-1] + pd.DateOffset(months=1), periods=len(future_t), freq='MS')
future_df = pd.DataFrame({
    'date': future_dates,
    'total_enrolments': future_predictions,
    'trend_pred': future_predictions
})

print("Future predictions DataFrame created:")
print(future_df.head())

"""concatenate the `monthly_enrolment_ts` DataFrame with the `future_df` DataFrame to create a single DataFrame for plotting both actual and forecasted trends,

```
# This is formatted as code
```



"""

combined_enrolment_trend = pd.concat([monthly_enrolment_ts[['date', 'total_enrolments', 'trend_pred']], future_df[['date', 'total_enrolments', 'trend_pred']]], ignore_index=True)

print("Combined DataFrame with actual and forecasted trends created:")
print(combined_enrolment_trend.head())
print(combined_enrolment_trend.tail())

"""
create a line plot visualizing the actual 'total_enrolments' and the 'trend_pred' (including the forecasted values) against the 'date' column, and add appropriate titles, axis labels, and a legend to the plot,

"""

plt.figure(figsize=(14, 7))
sns.lineplot(data=combined_enrolment_trend, x='date', y='total_enrolments', label='Actual Enrolments', marker='o')
sns.lineplot(data=combined_enrolment_trend, x='date', y='trend_pred', label='Predicted Trend & Forecast', linestyle='--', color='red')
plt.title('Monthly Enrolment: Actual vs. Predicted Trend with Forecast')
plt.xlabel('Date')
plt.ylabel('Total Enrolments')
plt.xticks(rotation=45)
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

print("Line plot for actual vs. predicted enrolment trend with forecast generated.")

"""## Saving Cleaned and Processed Datasets

save the `demographics` DataFrame to a CSV file named 'processed_demographics.csv' without the index,
"""

demographics.to_csv('processed_demographics.csv', index=False)
print("Saved 'processed_demographics.csv'")

"""I will save the `enrolment` DataFrame to a CSV file named 'processed_enrolment.csv' without the index,

"""

enrolment.to_csv('processed_enrolment.csv', index=False)
print("Saved 'processed_enrolment.csv'")

"""
I will save the `merged_df` DataFrame to a CSV file named 'integrated_enrolment_demographics.csv' without the index,

"""

merged_df.to_csv('integrated_enrolment_demographics.csv', index=False)
print("Saved 'integrated_enrolment_demographics.csv'")

"""I will save the `monthly_enrolment_ts` DataFrame to a CSV file named 'monthly_enrolment_trends.csv' without the index,


"""

monthly_enrolment_ts.to_csv('monthly_enrolment_trends.csv', index=False)
print("Saved 'monthly_enrolment_trends.csv'")

"""I will save the `agg_demographics` DataFrame to a CSV file named 'aggregated_demographics.csv' without the index,


"""

agg_demographics.to_csv('aggregated_demographics.csv', index=False)
print("Saved 'aggregated_demographics.csv'")

"""I will save the `agg_enrolment` DataFrame to a CSV file named 'aggregated_enrolment.csv' without the index,


"""

agg_enrolment.to_csv('aggregated_enrolment.csv', index=False)
print("Saved 'aggregated_enrolment.csv'")

"""I will print a final confirmation message indicating that all datasets.


"""

print("All cleaned and processed datasets have been saved.")

"""## Summary:

### Data Analysis Key Findings

*   **Robust Data Cleaning & Preprocessing**:
    *   Initial datasets were substantial, with `raw_demographics` at (2,071,700, 6) and `raw_enrolment` at (1,006,029, 7) rows.
    *   Duplicate removal was critical, with 473,601 duplicates removed from demographic data and 22,957 from enrolment data.
    *   Date conversion and subsequent `NaT` handling led to significant data reduction: 921,732 rows (57.68%) dropped from demographics and 663,354 rows (67.48%) from enrolment due to invalid date entries.
    *   Text standardization for 'state' and 'district' columns ensured consistency.
    *   The final cleaned DataFrames were `demographics` (676,367, 6) and `enrolment` (319,718, 7), both with 0% missing values.
*   **Comprehensive Feature Engineering**:
    *   Time-based features (`year`, `month`, `quarter`) were extracted to enable temporal analysis.
    *   Aggregated age groups (`total_population`, `total_enrolments`) and their proportions were created, providing normalized views of population segments and enrolment rates.
*   **Effective Outlier Treatment**:
    *   IQR-based capping was applied to numerical count columns. Significant numbers of values were capped: for demographics, 65,021 in `demo_age_5_17`, 75,709 in `demo_age_17_`, and 76,543 in `total_population`; for enrolment, 35,304 in `age_0_5`, 49,788 in `age_5_17`, 14,919 in `age_18_greater`, and 27,591 in `total_enrolments`. This treatment reduced the influence of extreme values, as visualized by boxplots.
*   **Integrated and Aggregated Dataset**:
    *   DataFrames were aggregated by common dimensions (`state`, `district`, `year`, `month`) into `agg_demographics` (11,749 entries) and `agg_enrolment` (10,991 entries).
    *   An inner merge successfully created `merged_df` (10,921 entries, 16 columns), providing a unified dataset for holistic analysis.
*   **Key Univariate Trends (Visualized by Histograms and Bar Charts)**:
    *   Distributions of demographic and enrolment counts were visualized, highlighting their spread and frequency.
    *   Bar charts identified the top 10 states and districts by total enrolments, revealing regional disparities.
    *   Temporal patterns of total enrolments by year and month were displayed, indicating overall growth and potential seasonality.
    *   Line plots illustrated overall monthly trends for total enrolments and total population, showing their evolution over time.
*   **Intervariable Relationships and Patterns (Visualized by Grouped Bar Charts, Boxplots, Line Plots, and Heatmaps)**:
    *   Grouped bar charts compared age-group specific enrolments across the top 10 states, revealing variations in enrolment composition.
    *   Boxplots showed the distribution and variability of total enrolments across top states.
    *   Line plots displayed distinct monthly enrolment trends for the top 5 states, indicating varying growth trajectories.
    *   A heatmap effectively visualized enrolment intensity across states and time periods, allowing for quick identification of high-activity regions and periods.
*   **Anomaly Detection**:
    *   Anomalies in monthly total enrolments were identified using a 2-standard deviation threshold around the mean (mean: 96923.92, standard deviation: 25334.43), indicating periods of unusually high or low enrolment activity. These were clearly shown on a time series scatter plot.
*   **Predictive Trend Analysis**:
    *   A linear regression model provided a predictive trend for monthly enrolments, forecasting 6 months into the future. The visualization showed a clear projection of future growth based on historical patterns.
*   **Data Accessibility**: All cleaned, processed, and integrated datasets (e.g., `processed_demographics.csv`, `integrated_enrolment_demographics.csv`) were saved as CSV files for easy access and further use in business intelligence tools.

"""

